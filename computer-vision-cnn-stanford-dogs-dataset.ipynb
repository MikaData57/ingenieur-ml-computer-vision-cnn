{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![baner_dogs](http://www.mf-data-science.fr/images/projects/dogs.jpg)\n# <div style=\"padding:5px; margin-top:-40px; background: #343434; border-bottom: 2px solid #e4bf13; color:white; text-align:center !important;\" id=\"intro\">Détection de race de chien<br/>à partir d'images grâce aux <br/>réseaux de neurones à convolution</div>\n\nL'objectif de ce Notebook est de détailler la mise en place d'un **algorithme de détection de la race du chien sur une photo**, afin d'accélérer le travail d’indexation dans une base de données.\n\n### Les contraintes imposées :\n- **Pré-processer les images** avec des techniques spécifiques *(e.g. whitening, equalization, éventuellement modification de la taille des images)*.\n- Réaliser de la **data augmentation** *(mirroring, cropping...)*.\n- Mise en oeuvre de 2 approches de l'utilisation des CNN :\n    - Réaliser un réseau de neurones CNN from scratch en optimisant les paramètres.     \n    - Utiliser le transfert learning et ainsi utiliser un réseau déjà entrainé.","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:#343434\" id=\"sommaire\">Sommaire</span>\n1. [Preprocessing des images](#section_1)     \n    1.1. [Visualisation de la liste des races (classes) et un exemple de données](#section_1_1)     \n    1.2. [Modification des histogrammes des images](#section_1_2)","metadata":{}},{"cell_type":"code","source":"# Import libraries\nimport os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2 as cv","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-07-15T12:32:28.089646Z","iopub.execute_input":"2021-07-15T12:32:28.090297Z","iopub.status.idle":"2021-07-15T12:32:28.094569Z","shell.execute_reply.started":"2021-07-15T12:32:28.090259Z","shell.execute_reply":"2021-07-15T12:32:28.093783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:#343434\" id=\"section_1\">Preprocessing des images</span>\n\nPour commencer, nous allons rapidement analyser les données en regardant notamment l'état de répartition des races de chiens dans le répertoire images :\n\n## <span style=\"color:#343434\" id=\"section_1_1\">Visualisation de la liste des races *(classes)* et un exemple de données.</span>","metadata":{}},{"cell_type":"code","source":"# Define path to data\nannotations_dir = '../input/stanford-dogs-dataset/annotations/Annotation' \nimages_dir = '../input/stanford-dogs-dataset/images/Images'","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:45:31.463567Z","iopub.execute_input":"2021-07-15T11:45:31.463937Z","iopub.status.idle":"2021-07-15T11:45:31.468546Z","shell.execute_reply.started":"2021-07-15T11:45:31.463904Z","shell.execute_reply":"2021-07-15T11:45:31.467365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of classes (dogs breeds)\nbreed_list = os.listdir(images_dir)\nprint(\"Number of breeds in dataset:\", (len(breed_list)))","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:45:34.433793Z","iopub.execute_input":"2021-07-15T11:45:34.434213Z","iopub.status.idle":"2021-07-15T11:45:34.496917Z","shell.execute_reply.started":"2021-07-15T11:45:34.434175Z","shell.execute_reply":"2021-07-15T11:45:34.495788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"120 races de chien sont donc présentes dans notre jeu de données, ce qui représente **120 classes pour notre classifier**.\nNous allons à présent compter le nombre d'images de chaque race afin de vérifier si la distribution est équitable entre les classes :","metadata":{}},{"cell_type":"code","source":"# Count number of pictures for each breed\ndf_breeds = pd.DataFrame(\n    index=[breed.split('-',1)[1]\n           for breed in breed_list],\n    data=[len(os.listdir(images_dir + \"/\" + name))\n          for name in breed_list],\n    columns=[\"num_pictures\"])\n\n# Plot results\nfig, ax = plt.subplots(1, 1, figsize=(25,12))\ndf_breeds.plot(kind=\"bar\",\n               legend=False,\n               ax=ax)\nax.axhline(df_breeds[\"num_pictures\"].mean(),\n           color='r', alpha=.7,\n           linestyle='--',\n           label=\"Mean of pictures\")\nplt.title(\"Number of pictures for each \"\\\n          \"dogs breeds of Dataset\",\n          color=\"#343434\", fontsize=22)\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On remarque que les races de chien sont toutes bien alimentées en images. La moyenne se situe à 171 photos par classe. Aucune race n'est sous représentée nous pouvons donc toutes les conserver pour le moment.\n\n**Regardons quelques exemples des photos par races** disponibles dans la base d'étude :","metadata":{}},{"cell_type":"code","source":"def show_images_classes(path, classes, num_sample):\n    \"\"\"This function is used to display the first \n    n images of a directory passed as an argument. \n    It is adapted to subdirectories. \n    \n    The matplotlib.image library must be loaded \n    with the alias mpimg. \n\n    Parameters\n    ----------------------------------------\n    path : string\n        Link of root directory\n    classes : string \n        Name of the subdirectory\n    num_smaple : integer\n        Number of picture to show\n    ----------------------------------------\n    \"\"\"\n    fig = plt.figure(figsize=(20,20))\n    fig.patch.set_facecolor('#343434')\n    plt.suptitle(\"{}\".format(classes.split(\"-\")[1]), y=.83,\n                 color=\"white\", fontsize=22)\n    images = os.listdir(path + \"/\" + classes)[:num_sample]\n    for i in range(num_sample):\n        img = mpimg.imread(path+\"/\"+classes+\"/\"+images[i])\n        plt.subplot(num_sample/5+1, 5, i+1)\n        plt.imshow(img)\n        plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T14:20:33.539326Z","iopub.execute_input":"2021-07-15T14:20:33.539691Z","iopub.status.idle":"2021-07-15T14:20:33.547167Z","shell.execute_reply.started":"2021-07-15T14:20:33.53966Z","shell.execute_reply":"2021-07-15T14:20:33.546405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in np.random.randint(0, len(breed_list), size=3):\n    show_images_classes(images_dir, breed_list[i], 5)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T14:20:38.830202Z","iopub.execute_input":"2021-07-15T14:20:38.830804Z","iopub.status.idle":"2021-07-15T14:20:40.269995Z","shell.execute_reply.started":"2021-07-15T14:20:38.830765Z","shell.execute_reply":"2021-07-15T14:20:40.268812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Avec un set d'image relativement important, les expositions, contraste, ... sont relativement différents pour chaque photo. Nous allons à présent utiliser des méthodes basées sur les histogrammes de ces images pour pre-processer au mieux ces données.\n\n## <span style=\"color:#343434\" id=\"section_1_2\">Modification des histogrammes des images</span>\n\nL'histogramme d'une image numérique est une courbe statistique représentant la **répartition de ses pixels selon leur intensité**. Commençons par regarder une image en particulier.\n\nNous allons transformer l'image dans différents codages couleurs. Le système de codage **YUV** est créé depuis une source RVB. Il est codé en trois composantes : **Y** représente la luminance *(informations de luminosité)* tandis que les deux autres (**U** et **V**) sont des données de chrominance *(informations de couleur)*. Ce format nous permet de visualiser au mieux l'histogramme pour les 3 dimensions :","metadata":{}},{"cell_type":"code","source":"# Define test image\nimg_test = (images_dir \n            + \"/\" \n            + \"n02085782-Japanese_spaniel/n02085782_1626.jpg\")\nimg_test = cv.imread(img_test)\n\n# Transform image with differents color sets\nimg_RGB = cv.cvtColor(img_test, cv.COLOR_BGR2RGB)\nimg_grayscale = cv.cvtColor(img_test, cv.COLOR_RGB2GRAY)\nimg_YUV = cv.cvtColor(img_test,cv.COLOR_BGR2YUV)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:43:23.367471Z","iopub.execute_input":"2021-07-15T15:43:23.367858Z","iopub.status.idle":"2021-07-15T15:43:23.382559Z","shell.execute_reply.started":"2021-07-15T15:43:23.367806Z","shell.execute_reply":"2021-07-15T15:43:23.381466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create histogram\ndef plot_histogram(init_img, convert_img):\n    hist, bins = np.histogram(\n                    convert_img[1].flatten(),\n                    256, [0,256])\n    # Cumulative Distribution Function\n    cdf = hist.cumsum()\n    cdf_normalized = cdf * float(hist.max()) / cdf.max()\n\n    # Plot histogram\n    fig = plt.figure(figsize=(25,6))\n    plt.subplot(1, 3, 1)\n    plt.imshow(init_img[1])\n    plt.title(\"{} Image\".format(init_img[0]), \n              color=\"#343434\")\n    plt.subplot(1, 3, 2)\n    plt.imshow(convert_img[1])\n    plt.title(\"{} Image\".format(convert_img[0]), \n              color=\"#343434\")\n    plt.subplot(1, 3, 3)\n    plt.plot(cdf_normalized, \n             color='r', alpha=.7,\n             linestyle='--')\n    plt.hist(convert_img[1].flatten(),256,[0,256])\n    plt.xlim([0,256])\n    plt.legend(('cdf','histogram'), loc = 'upper left')\n    plt.title(\"Histogram\", color=\"#343434\")\n    plt.suptitle(\"Histogram and cumulative \"\\\n                 \"distribution for test image\",\n              color=\"black\", fontsize=22, y=.98)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:42:40.060756Z","iopub.execute_input":"2021-07-15T15:42:40.061177Z","iopub.status.idle":"2021-07-15T15:42:40.090599Z","shell.execute_reply.started":"2021-07-15T15:42:40.061143Z","shell.execute_reply":"2021-07-15T15:42:40.089338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_histogram([\"RGB\", img_RGB], [\"YUV\", img_YUV])","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:42:44.91578Z","iopub.execute_input":"2021-07-15T15:42:44.916274Z","iopub.status.idle":"2021-07-15T15:42:46.010667Z","shell.execute_reply.started":"2021-07-15T15:42:44.91624Z","shell.execute_reply":"2021-07-15T15:42:46.009747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On constate ici des pics importants au centre de l'histogram. Dans le cadre d'une bonne égalisation (amélioration du contraste), il est nécessaire de répartir la lumière dans tout le spectre de l'image. \n\n**Testons l'égalisation avec OpenCV :**     \nL'intérêt de convertir l'image dans l'espace colorimétrique YUV est de pouvoir agir sur le canal \"luminance\" (Y) indépendamment des autres canaux de chrominance. Nous allons donc réaliser l'égalisation sur ce seul canal Y :","metadata":{}},{"cell_type":"code","source":"# Equalization\nimg_YUV[:,:,0] = cv.equalizeHist(img_YUV[:,:,0])\nimg_equ = cv.cvtColor(img_YUV, cv.COLOR_YUV2RGB)\nplot_histogram([\"RGB\", img_RGB], [\"Equalized\", img_equ])","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:44:17.355984Z","iopub.execute_input":"2021-07-15T15:44:17.356375Z","iopub.status.idle":"2021-07-15T15:44:18.441163Z","shell.execute_reply.started":"2021-07-15T15:44:17.356339Z","shell.execute_reply":"2021-07-15T15:44:18.440007Z"},"trusted":true},"execution_count":null,"outputs":[]}]}